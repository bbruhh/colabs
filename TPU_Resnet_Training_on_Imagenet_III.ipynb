{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU Resnet Training on Imagenet III",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/christianmerkwirth/colabs/blob/master/TPU_Resnet_Training_on_Imagenet_III.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ty5g5lT2zpVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # colab.research.google.com specific\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  import json\n",
        "  import os\n",
        "  from google.colab import auth\n",
        "\n",
        "  !git clone https://github.com/tensorflow/tpu.git\n",
        "  !cp  tpu/models/official/resnet/resnet_main.py  .\n",
        "  !mv tpu/models/official ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ih0PCgV-0sI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now run the main to set up flags and constant. The main function should not be executed.\n",
        "\n",
        "import resnet_main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BFftrYfhfZIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "from official.resnet import imagenet_input\n",
        "from official.resnet import lars_util\n",
        "from official.resnet import resnet_model\n",
        "from tensorflow.contrib import summary\n",
        "from tensorflow.contrib.tpu.python.tpu import async_checkpoint\n",
        "from tensorflow.contrib.training.python.training import evaluation\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "from tensorflow.python.estimator import estimator\n",
        "\n",
        "\n",
        "def main(FLAGS):\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  # pass the args as params so the model_fn can use\n",
        "  # the TPU specific args\n",
        "\n",
        "  params = FLAGS.flag_values_dict()\n",
        "    \n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "      FLAGS.tpu if (FLAGS.tpu or FLAGS.use_tpu) else '')\n",
        "\n",
        "  if FLAGS.use_async_checkpointing:\n",
        "    save_checkpoints_steps = None\n",
        "  else:\n",
        "    save_checkpoints_steps = max(100, FLAGS.iterations_per_loop)\n",
        "  config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=FLAGS.model_dir,\n",
        "      save_checkpoints_steps=save_checkpoints_steps,\n",
        "      log_step_count_steps=FLAGS.log_step_count_steps,\n",
        "      session_config=tf.ConfigProto(\n",
        "          graph_options=tf.GraphOptions(\n",
        "              rewrite_options=rewriter_config_pb2.RewriterConfig(\n",
        "                  disable_meta_optimizer=True))),\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "          num_shards=FLAGS.num_cores,\n",
        "          per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "  resnet_classifier = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      model_fn=resnet_main.resnet_model_fn,\n",
        "      config=config,\n",
        "      train_batch_size=FLAGS.train_batch_size,\n",
        "      eval_batch_size=FLAGS.eval_batch_size,\n",
        "      export_to_tpu=False)\n",
        "  assert FLAGS.precision == 'bfloat16' or FLAGS.precision == 'float32', (\n",
        "      'Invalid value for --precision flag; must be bfloat16 or float32.')\n",
        "  tf.logging.info('Precision: %s', FLAGS.precision)\n",
        "  use_bfloat16 = FLAGS.precision == 'bfloat16'\n",
        "\n",
        "  tf.logging.info('Using dataset: %s', FLAGS.data_dir)\n",
        "  imagenet_train, imagenet_eval = [\n",
        "      imagenet_input.ImageNetInput(\n",
        "          is_training=is_training,\n",
        "          data_dir=FLAGS.data_dir,\n",
        "          transpose_input=FLAGS.transpose_input,\n",
        "          cache=FLAGS.use_cache and is_training,\n",
        "          num_parallel_calls=FLAGS.num_parallel_calls,\n",
        "          use_bfloat16=use_bfloat16) for is_training in [True, False]\n",
        "  ]\n",
        "\n",
        "  steps_per_epoch = FLAGS.num_train_images // FLAGS.train_batch_size\n",
        "  eval_steps = FLAGS.num_eval_images // FLAGS.eval_batch_size\n",
        "\n",
        "  if FLAGS.mode == 'eval':\n",
        "    # Run evaluation when there's a new checkpoint\n",
        "    for ckpt in evaluation.checkpoints_iterator(\n",
        "        FLAGS.model_dir, timeout=FLAGS.eval_timeout):\n",
        "      tf.logging.info('Starting to evaluate.')\n",
        "      try:\n",
        "        start_timestamp = time.time()  # This time will include compilation time\n",
        "        eval_results = resnet_classifier.evaluate(\n",
        "            input_fn=imagenet_eval.input_fn,\n",
        "            steps=eval_steps,\n",
        "            checkpoint_path=ckpt)\n",
        "        elapsed_time = int(time.time() - start_timestamp)\n",
        "        tf.logging.info('Eval results: %s. Elapsed seconds: %d',\n",
        "                        eval_results, elapsed_time)\n",
        "\n",
        "        # Terminate eval job when final checkpoint is reached\n",
        "        current_step = int(os.path.basename(ckpt).split('-')[1])\n",
        "        if current_step >= FLAGS.train_steps:\n",
        "          tf.logging.info(\n",
        "              'Evaluation finished after training step %d', current_step)\n",
        "          break\n",
        "\n",
        "      except tf.errors.NotFoundError:\n",
        "        # Since the coordinator is on a different job than the TPU worker,\n",
        "        # sometimes the TPU worker does not finish initializing until long after\n",
        "        # the CPU job tells it to start evaluating. In this case, the checkpoint\n",
        "        # file could have been deleted already.\n",
        "        tf.logging.info('Checkpoint %s no longer exists, skipping checkpoint', ckpt)\n",
        "\n",
        "  else:   # FLAGS.mode == 'train' or FLAGS.mode == 'train_and_eval'\n",
        "    current_step = estimator._load_global_step_from_checkpoint_dir(FLAGS.model_dir)  # pylint: disable=protected-access,line-too-long\n",
        "    steps_per_epoch = FLAGS.num_train_images // FLAGS.train_batch_size\n",
        "\n",
        "    tf.logging.info('Training for %d steps (%.2f epochs in total). Current'\n",
        "                    ' step %d.',\n",
        "                    FLAGS.train_steps,\n",
        "                    FLAGS.train_steps / steps_per_epoch,\n",
        "                    current_step)\n",
        "\n",
        "    start_timestamp = time.time()  # This time will include compilation time\n",
        "\n",
        "    if FLAGS.mode == 'train':\n",
        "      hooks = []\n",
        "      if FLAGS.use_async_checkpointing:\n",
        "        hooks.append(\n",
        "            async_checkpoint.AsyncCheckpointSaverHook(\n",
        "                checkpoint_dir=FLAGS.model_dir,\n",
        "                save_steps=max(100, FLAGS.iterations_per_loop)))\n",
        "      resnet_classifier.train(\n",
        "          input_fn=imagenet_train.input_fn,\n",
        "          max_steps=FLAGS.train_steps,\n",
        "          hooks=hooks)\n",
        "\n",
        "    else:\n",
        "      assert FLAGS.mode == 'train_and_eval'\n",
        "      while current_step < FLAGS.train_steps:\n",
        "        # Train for up to steps_per_eval number of steps.\n",
        "        # At the end of training, a checkpoint will be written to --model_dir.\n",
        "        next_checkpoint = min(current_step + FLAGS.steps_per_eval,\n",
        "                              FLAGS.train_steps)\n",
        "        resnet_classifier.train(\n",
        "            input_fn=imagenet_train.input_fn, max_steps=next_checkpoint)\n",
        "        current_step = next_checkpoint\n",
        "\n",
        "        tf.logging.info('Finished training up to step %d. Elapsed seconds %d.',\n",
        "                        next_checkpoint, int(time.time() - start_timestamp))\n",
        "\n",
        "        # Evaluate the model on the most recent model in --model_dir.\n",
        "        # Since evaluation happens in batches of --eval_batch_size, some images\n",
        "        # may be excluded modulo the batch size. As long as the batch size is\n",
        "        # consistent, the evaluated images are also consistent.\n",
        "        tf.logging.info('Starting to evaluate.')\n",
        "        eval_results = resnet_classifier.evaluate(\n",
        "            input_fn=imagenet_eval.input_fn,\n",
        "            steps=FLAGS.num_eval_images // FLAGS.eval_batch_size)\n",
        "        tf.logging.info('Eval results at step %d: %s',\n",
        "                        next_checkpoint, eval_results)\n",
        "\n",
        "      elapsed_time = int(time.time() - start_timestamp)\n",
        "      tf.logging.info('Finished training up to step %d. Elapsed seconds %d.',\n",
        "                      FLAGS.train_steps, elapsed_time)\n",
        "\n",
        "    if FLAGS.export_dir is not None:\n",
        "      tf.logging.info('Starting to export model.')\n",
        "      resnet_classifier.export_savedmodel(\n",
        "          export_dir_base=FLAGS.export_dir,\n",
        "          serving_input_receiver_fn=image_serving_input_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57bqoXEAcPiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# colab.research.google.com specific\n",
        "import sys\n",
        "from absl import flags\n",
        "import absl.logging as _logging\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  import json\n",
        "  import os\n",
        "  from google.colab import auth\n",
        "\n",
        "  # Authenticate to access GCS bucket\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # Parse FLAGS parsing.\n",
        "  FLAGS(['resnet_trainer'])\n",
        "  \n",
        "  # Change parameters according to your setup.\n",
        "  FLAGS.train_steps = 1200000\n",
        "  FLAGS.model_dir = 'gs://tpu-cmerk-2/imagenet/models/resnet/20181022_003'\n",
        "  FLAGS.data_dir = 'gs://tpu-cmerk-2/imagenet/train'\n",
        "\n",
        "  # When connected to the TPU runtime\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    tpu_grpc = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "    FLAGS.tpu = tpu_grpc\n",
        "    FLAGS.use_tpu = True\n",
        "\n",
        "    # Upload credentials to the TPU\n",
        "    with tf.Session(tpu_grpc) as sess:\n",
        "      data = json.load(open('/content/adc.json'))\n",
        "      tf.contrib.cloud.configure_gcs(sess, credentials=data)\n",
        "\n",
        "    \n",
        "main(FLAGS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-GWwCat4Ve6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}