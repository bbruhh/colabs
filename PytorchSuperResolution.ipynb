{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchSuperResolution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/christianmerkwirth/colabs/blob/master/PytorchSuperResolution.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "KuekWpR9HxBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Colab notebook demonstrates how to install PyTorch on a Colab and walks the user through the [PyTorch SuperResolution example](https://https://github.com/pytorch/examples/tree/master/super_resolution)."
      ]
    },
    {
      "metadata": {
        "id": "Anp4xXR8BUgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZvm2ezh8QeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir -I pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbFrxmWQBZXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r examples\n",
        "!git clone https://github.com/pytorch/examples.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIfSKuXkBfoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Change working directory into the git repo.\n",
        "import os\n",
        "os.chdir('examples/super_resolution/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQOqsrFo7NEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufp8PTn_BrdK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "\n",
        "from math import log10\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from model import Net\n",
        "from data import get_training_set, get_test_set\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch Super Res Example')\n",
        "parser.add_argument('--upscale_factor', type=int, default=3, help=\"super resolution upscale factor\")\n",
        "parser.add_argument('--batchSize', type=int, default=4, help='training batch size')\n",
        "parser.add_argument('--testBatchSize', type=int, default=100, help='testing batch size')\n",
        "parser.add_argument('--nEpochs', type=int, default=30, help='number of epochs to train for')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='Learning Rate. Default=0.01')\n",
        "parser.add_argument('--cuda', action='store_true', help='use cuda?')\n",
        "parser.add_argument('--threads', type=int, default=4, help='number of threads for data loader to use')\n",
        "parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
        "\n",
        "\n",
        "opt = parser.parse_args(['--cuda'])\n",
        "\n",
        "print(opt)\n",
        "\n",
        "if opt.cuda and not torch.cuda.is_available():\n",
        "    raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "torch.manual_seed(opt.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if opt.cuda else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "print('===> Loading datasets')\n",
        "train_set = get_training_set(opt.upscale_factor)\n",
        "test_set = get_test_set(opt.upscale_factor)\n",
        "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n",
        "\n",
        "print('===> Building model')\n",
        "model = Net(upscale_factor=opt.upscale_factor).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    for iteration, batch in enumerate(training_data_loader, 1):\n",
        "        input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(input), target)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.item()))\n",
        "\n",
        "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
        "\n",
        "\n",
        "def test():\n",
        "    avg_psnr = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in testing_data_loader:\n",
        "            input, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "            prediction = model(input)\n",
        "            mse = criterion(prediction, target)\n",
        "            psnr = 10 * log10(1 / mse.item())\n",
        "            avg_psnr += psnr\n",
        "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
        "\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
        "    torch.save(model, model_out_path)\n",
        "    print(\"Checkpoint saved to {}\".format(model_out_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIINLnqpesG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Workaround around registration problem\n",
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxSzsPmGCFyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If this fails, restart the runtime and repeat previous cells beginning from\n",
        "# the cell where we change the workding directory.\n",
        "\n",
        "for epoch in range(1, 26):\n",
        "    train(epoch)\n",
        "    test()\n",
        "    checkpoint(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBkq5X0bDfoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img = Image.open(\"dataset/BSDS300/images/test/16077.jpg\").convert('YCbCr')\n",
        "y, cb, cr = img.split()\n",
        "\n",
        "img_to_tensor = ToTensor()\n",
        "input = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])\n",
        "\n",
        "if opt.cuda:\n",
        "    model = model.cuda()\n",
        "    input = input.cuda()\n",
        "\n",
        "out = model(input)\n",
        "out = out.cpu()\n",
        "out_img_y = out[0].detach().numpy()\n",
        "out_img_y *= 255.0\n",
        "out_img_y = out_img_y.clip(0, 255)\n",
        "out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n",
        "\n",
        "out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)\n",
        "out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)\n",
        "out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOT-5tL4FYZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "imshow(np.asarray(img.convert('RGB')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJK4opqlFZfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imshow(np.asarray(out_img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_aQPwfS5HH41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_img.save('/tmp/upscaled_image.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oiv4Rp-Hw37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -la /tmp/upscaled_image.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvN4ItF7KbIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}